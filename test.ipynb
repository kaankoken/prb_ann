{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#%%\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pylot\n",
        "\n",
        "from datetime import  tzinfo, timezone\n",
        "from datetime import datetime as dt\n",
        "from google.colab import drive, files\n",
        "\n",
        "#%%\n",
        "class PreProcess:\n",
        "    #reads csv file at the given path\n",
        "    def read_file(self, path: str):\n",
        "        if path.startswith('/'):\n",
        "            path = '.' + path\n",
        "        elif not path.startswith('/') or not path.startswith('.'):\n",
        "            path = './' + path\n",
        "        else: pass\n",
        "        df = pd.read_csv(path)\n",
        "        return df\n",
        "\n",
        "    #converts the date time to timestamp\n",
        "    def convert_timestamps(self, data_frame: pd.DataFrame):\n",
        "        try:\n",
        "            tm = dt.strptime(data_frame, '%Y-%m-%d %H:%M:%S.%f %Z')\n",
        "        except ValueError:\n",
        "            tm = dt.strptime(data_frame, '%Y-%m-%d %H:%M:%S %Z')\n",
        "        converted = tm.timestamp() * 1000 \n",
        "        return converted\n",
        "    \n",
        "    def sort_values(self, data_frame: pd.DataFrame):\n",
        "        x = data_frame.groupby('user_id', sort=True)\n",
        "        t = []\n",
        "        [t.append(value) for key, value in x]\n",
        "        x = []\n",
        "        [x.append(i.sort_values('timestamp',ascending=True).reset_index(drop=True)) for i in t]\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def split_to_trip(self, data_frame: pd.DataFrame):\n",
        "        data_frame['trip'] = (data_frame['timestamp'] - data_frame[i]['timestamp'].shift(1) > 60000).cumsum()\n",
        "        return data_frame\n",
        "\n",
        "    def divide_to_trip(self, data: pd.DataFrame):\n",
        "        trip = data.index[np.where(data['trip'] - data['trip'].shift(1) > 0)]\n",
        "        tripCount = trip.values.size\n",
        "        data = data.drop('trip', axis=1)\n",
        "\n",
        "        changedData = []\n",
        "\n",
        "        endpoint = 0\n",
        "        if (tripCount > 0):\n",
        "            for i in range(0, tripCount):\n",
        "                if (i == 0):\n",
        "                    changedData.append(data.loc[0: trip[i] -1].reset_index(drop=True))\n",
        "                else:\n",
        "                    changedData.append(data.loc[trip[i - 1]: trip[i] -1].reset_index(drop=True))\n",
        "\n",
        "                endpoint = i\n",
        "            changedData.append(data.loc[trip[endpoint]: len(data)].reset_index(drop=True))\n",
        "        else:\n",
        "            changedData.append(data.loc[0: len(data)].reset_index(drop=True))\n",
        "\n",
        "        return changedData\n",
        "    \n",
        "    def flatten(self, data: pd.DataFrame):\n",
        "        x = [e for sl in data for e in sl]\n",
        "        return x\n",
        "    \n",
        "    def drop_if_small(self, data: pd.DataFrame, size: int):\n",
        "        y = []\n",
        "        for i in data:\n",
        "            if len(i) > size:\n",
        "                y.append(i)\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def find_min_max(self, value: pd.DataFrame):\n",
        "        max = value.max()\n",
        "        min = value.min()\n",
        "        return min, max\n",
        "\n",
        "    def divide_by_angle_norm(self, data: pd.DataFrame, d_type: str):\n",
        "        if (d_type == 'lat'):\n",
        "            normalized_data = data / 180\n",
        "        else:\n",
        "            normalized_data = data / 360\n",
        "        return normalized_data\n",
        "\n",
        "    def denorm_angle(self, result):\n",
        "        denorm_x = result[0][0][1] * 180\n",
        "        denorm_y = result[0][0][2] * 360\n",
        "\n",
        "        return denorm_x, denorm_y\n",
        "\n",
        "    def min_max_norm(self, data: pd.DataFrame, min: int, max: int):\n",
        "        if (max - min == 0):\n",
        "            max = 1 \n",
        "        normalized_data = ((data - min) / ((max - min)))\n",
        "        return normalized_data\n",
        "\n",
        "    def denorm_min_max(self, result, min: int, max: int, key: str):\n",
        "        if (key == 'lat'):\n",
        "            denormalized = result[0][0][1] * max - result[0][0][1] * min + min\n",
        "        else:\n",
        "            denormalized = result[0][0][2] * max - result[0][0][2] * min + min\n",
        "        return denormalized\n",
        "\n",
        "    def create_dataset(self, data: pd.DataFrame, n_steps: int):\n",
        "        X, y = list(), list()\n",
        "        for i in range(len(data)):\n",
        "          # find the end of this pattern\n",
        "          end_ix = i + n_steps\n",
        "          # check if we are beyond the dataset\n",
        "          if end_ix > len(data)-1:\n",
        "            break\n",
        "          # gather input and output parts of the pattern\n",
        "          seq_x, seq_y = data.iloc[i:end_ix, :], data.iloc[end_ix, :]\n",
        "          X.append(np.array(seq_x))\n",
        "          y.append(np.array(seq_y))\n",
        "        return X, y\n",
        "\n",
        "    '''def fitData(self, value: pd.DataFrame, min: int, max: int):\n",
        "        fitedData = np.interp(value, (min, max), (0, +1))\n",
        "        return fitedData'''\n",
        "\n",
        "#%%\n",
        "class GoogleDrive:\n",
        "    #mounts the drive and change the file path to google drive's path\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/gdrive')\n",
        "        os.chdir('./gdrive/My Drive')\n",
        "        return\n",
        "    \n",
        "    #creates file at the given path\n",
        "    def create_file(self, path: str):\n",
        "        os.mkdir(path)\n",
        "        return\n",
        "    \n",
        "    #deletes the file at the given path\n",
        "    def remove_file(self, path: str):\n",
        "        os.rmdir(path)\n",
        "        return\n",
        "\n",
        "    #it allows you to upload files to google drive\n",
        "    def upload_files(self):\n",
        "        uploaded = files.upload()\n",
        "        return\n",
        "#%%\n",
        "class Model:\n",
        "    def set_the_model(self, look_back):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(16, activation=\"relu\", input_shape=(look_back, 3),return_sequences=True)) #, stateful=True\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(LSTM(32, activation=\"relu\", return_sequences=True))\n",
        "        self.model.add(Dropout(0.2))\n",
        "        self.model.add(TimeDistributed(Dense(look_back)))\n",
        "        #self.model.add(Dense(3))\n",
        "        self.model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=['acc']) #mse\n",
        "        self.model.summary()\n",
        "    \n",
        "    def start_train(self, trainD1, trainD2):\n",
        "        es = EarlyStopping(monitor='loss', patience = 2, mode='min')\n",
        "        #for i in range(1, 7): #len(trainD1)\n",
        "          #x, y = trainD1[(i - 1) * 10357: i *10357], trainD2[(i - 1) * 10357: i *10357]\n",
        "        self.model.fit(trainD1, trainD1, epochs=100, batch_size = 32, verbose=1,  callbacks=[es])\n",
        "        #  self.model.reset_states()\n",
        "    \n",
        "    def predict_result(self, test_case):\n",
        "        value = self.model.predict(testCase, verbose=0)\n",
        "        return value\n",
        "#%%\n",
        "gdrive = GoogleDrive()\n",
        "pre_process = PreProcess()\n",
        "\n",
        "#%%\n",
        "gdrive.mount_drive()\n",
        "path = 'Colab Notebooks/bq-results-20190628-104852-awu4v6ig6fyq.csv'\n",
        "data_frame = pre_process.read_file(path)\n",
        "\n",
        "#%%\n",
        "data_frame['timestamp'] = data_frame['timestamp'].apply(pre_process.convert_timestamps)\n",
        "data_frame = pre_process.sort_values(data_frame)\n",
        "data_frame = pre_process.drop_if_small(data_frame, 4)\n",
        "\n",
        "#%%\n",
        "for i in range(0,len(data_frame)):\n",
        "    data_frame[i]['trip'] = (data_frame[i]['timestamp'] - data_frame[i]['timestamp'].shift(1) > 60000).cumsum()\n",
        "#%%\n",
        "for i in range(0,len(data_frame)):\n",
        "    data_frame[i] = pre_process.divide_to_trip(data_frame[i])\n",
        "data_frame = pre_process.flatten(data_frame)\n",
        "data_frame = pre_process.drop_if_small(data_frame, 4)\n",
        "\n",
        "#%%\n",
        "for i in data_frame:\n",
        "    min_lat, max_lat = pre_process.find_min_max(i['latitude'])\n",
        "    min_long, max_long = pre_process.find_min_max(i['longitude'])\n",
        "    min_time, max_time = pre_process.find_min_max(i['timestamp'])\n",
        "    i['latitude'] = pre_process.min_max_norm(i['latitude'], min_lat, max_lat)\n",
        "    i['longitude'] = pre_process.min_max_norm(i['longitude'], min_long, max_long)\n",
        "    i['timestamp'] = pre_process.min_max_norm(i['timestamp'], min_time, max_time)\n",
        "    i.drop('user_id', axis=1, inplace=True)\n",
        "\n",
        "#%%\n",
        "look_back = 3\n",
        "data_frame_copy = data_frame.copy()\n",
        "#data_frame_copy[0]['latitude'][0] = pre_process.denorm_min_max(data_frame_copy[0]['latitude'][0], lat[0][0], lat[0][1])\n",
        "\n",
        "#%%\n",
        "#work on single dataset\n",
        "\n",
        "for i in data_frame_copy:\n",
        "  if (len(i) == 19082):\n",
        "    x = i\n",
        "\n",
        "train_size = int(len(x) * 0.67)\n",
        "test_size = len(x) - train_size\n",
        "\n",
        "train = x[0: train_size]\n",
        "test = x[train_size: len(x)]\n",
        "\n",
        "train_x, train_y = pre_process.create_dataset(train, 3)\n",
        "test_x, test_y = pre_process.create_dataset(test, 3)\n",
        "\n",
        "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], 3)\n",
        "test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], 3)\n",
        "\n",
        "\n",
        "#%%\n",
        "model = Model()\n",
        "model.set_the_model(look_back)\n",
        "model.start_train(train_x, train_y)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}